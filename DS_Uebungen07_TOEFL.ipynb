{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity tests on TOEFL Similarity Questionnaire\n",
    "\n",
    "Resource: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "Other tests on TOEFL Similarity Test: https://aclweb.org/aclwiki/TOEFL_Synonym_Questions_(State_of_the_art) (if the link doesn't work, make sure you have the closing paranthesis in your URL!)\n",
    "\n",
    "The task for today is to pass the TOEFL similarity test with the aid of computational support. The tools we need:\n",
    "\n",
    "1. word vectors (taken from the GloVe resource)\n",
    "2. TOEFL similarity Questionnaire + answers for comparison\n",
    "3. cosine similarity for predicting the correct answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "We want to define the cosine similarity at an early stage of our code, since it is one of the main steps we need to take. Formula reminder:\n",
    "\n",
    "## $cos\\text{-}sim = \\frac{v\\cdot w}{||v||\\cdot ||w||}$\n",
    "\n",
    "The necessary parts for coding the formula you will find below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Instanciate the vectors\n",
    "v = np.array([1,2,3])\n",
    "u = np.array([1,2,3])\n",
    "\n",
    "# Numpy contains a function for the length of a vector\n",
    "#norm(vector)\n",
    "\n",
    "# Insert the cosine_similarity here, which takes two vectors v and u and computes the similarity between them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with files\n",
    "\n",
    "Before you start working with a file, you first need to declare a path to your file. The \"with open()\" method allow you to access the file and perform tasks on it. Please open your own dummy file and print out the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_file = \"C:/path/to/file.txt\"\n",
    "\n",
    "with open(path_to_file, 'r', encoding='utf-8') as f:\n",
    "    pass # Insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below defines two functions: cosine_sim() and compare_similarity(). The purpose of this piece of code is to compare the vectors of two words and give out their similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "embeddings_path = \"C:/path/to/file/glove.6B.300d.txt\"\n",
    "\n",
    "def cosine_sim(vec_1, vec_2):\n",
    "    return (vec_1/norm(vec_1)).dot((vec_2/norm(vec_2)))\n",
    "\n",
    "def compare_similarity(word_1, word_2):\n",
    "    \"\"\"This function takes two words, looks them up in a file of word vectors\n",
    "    and compares the cosine similarity of these vectors. It returns a dict\n",
    "    with the two word vectors and the cosine similarity between them.\n",
    "    \"\"\"\n",
    "    compare_words = {} # dict in which the word vectors are stored\n",
    "    with open(embeddings_path, 'r', encoding='utf-8') as emb_file: # opens the file with word_vectors\n",
    "        for word_vector in emb_file: # reads the file line by line: every line is a word vector in string format\n",
    "            word, vector = word_vector.split(' ', 1) # splits the vector string into two parts: word and vector\n",
    "            if word in [word_1.lower(), word_2.lower()]: # checks whether the word is one of the two words\n",
    "                compare_words[word] = (np.fromstring(vector, dtype='float', sep=' ')) # adds vectors to compare_words\n",
    "                if len(compare_words) == 2: # if compare_words contains two words the loop is broken\n",
    "                    break\n",
    "\n",
    "    if len(compare_words) != 2:\n",
    "        sim_of_words = 0.0\n",
    "    else:    \n",
    "        w_1, w_2 = compare_words.values()\n",
    "        sim_of_words = cosine_sim(w_1, w_2)\n",
    "        \n",
    "    return sim_of_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can perform the cosine similarity on our data, we need to access the required data and preprocess it. The code below reads both toefl-files, the questions and the corresponding answers. Please fill out the missing parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "toefl_qst_path = \"C:/path/to/file/toefl_qst.txt\"\n",
    "toefl_ans_path = \"C:/path/to/file/toefl_ans.txt\"\n",
    "\n",
    "def read_toefl():\n",
    "    questions_list = []\n",
    "    choices_dict = {}\n",
    "    \n",
    "    with open(toefl_qst_path, 'r', encoding='utf-8') as toefl_questions:\n",
    "        questions = toefl_questions.read()\n",
    "        questions = questions.split('\\n\\n')\n",
    " \n",
    "        for q in questions:\n",
    "            question = q.split()\n",
    "            target = question[1]\n",
    "            choices = question[2:]\n",
    "            letters = [c.rstrip('.') for c in choices[0::2]]\n",
    "            candidates = choices[1::2]\n",
    "            \n",
    "            for i,l in enumerate(letters):\n",
    "                choices_dict[l] = candidates[i]\n",
    "            \n",
    "            questions_list.append([target, choices_dict])\n",
    "            choices_dict = {}\n",
    "                \n",
    "    with open(toefl_ans_path, 'r', encoding='utf-8') as toefl_answers:\n",
    "        answers = []\n",
    "        for line in toefl_answers:\n",
    "            if line not in ['\\n']:\n",
    "                answer = line.split()[3]\n",
    "                answers.append(answer)\n",
    "    return questions_list, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put everything together!\n",
    "\n",
    "The read_toefl() function returns two lists: questions_list and answers. You will need only the questions_list at this point. The task is to access the target words and to calculate the similarity with their corresponding candidates. The result might look like:\n",
    "\n",
    "enormously  -  appropriately :  0.537885569727\n",
    "\n",
    "enormously  -  uniquely :  0.617749822949\n",
    "\n",
    "enormously  -  tremendously :  0.906292639466\n",
    "\n",
    "enormously  -  decidedly :  0.555241334939\n",
    "\n",
    "etc. ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_list, answers = read_toefl()\n",
    "\n",
    "for target, candidate in questions_list:\n",
    "    i = 0\n",
    "    while i < len(candidate):\n",
    "        for token in candidate.values():\n",
    "            print(target,' - ',token,': ', compare_similarity(target,token))\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step to take is to calculate the accuracy of our predictions. For this task, we require two lists: the list with the predicted results and the list with the actual results. \n",
    "\n",
    "The code below calculates the most promising candidate for the target word and returns its alphanumerical index as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_synonym(question):\n",
    "    #question = ['enormously', {'a':'appropriately','b':'uniquely','c':'tremendously','d':'decidedly'}]\n",
    "    target = question[0]\n",
    "    candidates = question[1]\n",
    "    \n",
    "    similarities = []\n",
    "    \n",
    "    for choice in candidates:\n",
    "        score = compare_similarity(target, candidates[choice])\n",
    "        similarities.append((choice, score))\n",
    "\n",
    "    prediction = max(similarities, key=lambda x:x[1])[0]\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task now is to write a code which gives these two lists as outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "questions_list, gold = read_toefl()\n",
    "\n",
    "for question in questions_list:\n",
    "    print(predict_synonym(question))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the accuracy score between our predictions and the correct answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "questions, gold = read_toefl()\n",
    "predictions = []\n",
    "\n",
    "for question in questions:\n",
    "    #print(question)\n",
    "    prediction = predict_synonym(question)\n",
    "    #print(prediction)\n",
    "    predictions.append(prediction)\n",
    "\n",
    "print(\"Accuracy for TOEFL test: \", accuracy_score(predictions, gold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for TOEFL test and 200-dim vector: 0.85\n",
    "\n",
    "Accuracy for TOEFL test and 300-dim vector: 0.8875"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
