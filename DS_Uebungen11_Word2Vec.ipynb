{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec with gensim\n",
    "\n",
    "\n",
    "Main source: https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/models/word2vec.py\n",
    "\n",
    "Reddit QA: https://www.kaggle.com/jiriroz/qa-jokes\n",
    "\n",
    "You will need to register in kaggle for the data. Either you do that or you write an e-mail to the author of this notebook.\n",
    "\n",
    "It is recommendet to install cython as well: gensim automatically access cython libraries which greatly increases the computation time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "import logging\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "# In case that the nltk tokenizer doesn't work, the problem might lie in missing libraries. In this case use the code below.\n",
    "# nltk.download()\n",
    "\n",
    "# For this notebook the library gensim, cython and plotly are used, but they are usually not pre-installed. For Anaconda:\n",
    "# conda install gensim, cython, plotly\n",
    "\n",
    "# for buffer information\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Include data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/question-answer-jokes/jokes.csv') #set path\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate your corpus\n",
    "\n",
    "Remark: the answers are appended at the end!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df['Question'].values.tolist()\n",
    "y = df['Answer'].values.tolist()\n",
    "\n",
    "corpus = x+y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tok_corp = [nltk.word_tokenize(sent) for sent in corpus] # tokenize the words in the corpus with nltk. It is up to you to preprocess the corpus as you like\n",
    "tok_corp = [[w.lower() for w in nltk.word_tokenize(text)] for text in corpus]\n",
    "\n",
    "# hint: word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate your Word2Vec!\n",
    "\n",
    "You will not see any math at the surface. All operations are computed in the background. Nevertheless, there are around 20 parameters which can be adjusted according to the task.\n",
    "\n",
    "\n",
    "\n",
    "CBOW: _predicting the word given its context_\n",
    "\n",
    "SG: _predicting the context given a word_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(tok_corp, min_count=1, size = 50)\n",
    "\n",
    "# 'gensim' is the library we use\n",
    "# 'models' is the class for creating different models\n",
    "# 'Word2Vec()' is the function we need. It takes, among others, the following parameters:\n",
    "\n",
    "# param: sentence: first attribute is for the corpus\n",
    "# param: size = 100: size of the vectors\n",
    "# param: alpha = 0.025: is the initial learning rate (will linearly drop to `min_alpha` as training progresses)\n",
    "# param: window: maximum distance between the current and predicted word within a sentence\n",
    "# param: min_count: ignore all words with total frequency lower than this\n",
    "# param: workers: number of threads to run in parallel\n",
    "# param: sg: skip-gram for activation sg = 1 (standard is 0)\n",
    "# param: iter: number of iterations over the corpus (default is 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i = 0\n",
    "#while i < 15:\n",
    "#    print(tok_corp[i])\n",
    "#    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the model!\n",
    "\n",
    "It is recommended to persist the model to the hard drive and make it accessible. This very model can be re-used for further training or other modification.\n",
    "\n",
    "Question: how does the file look like with the save() function? What is the problem here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Persist model to disk\n",
    "model.save('testmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.wv.save_word2vec_format('testmodel.txt', binary=False)\n",
    "\n",
    "# hint: function 'wv' for word vector\n",
    "# hint: function save_word2vec_format takes useful parameters..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load pre-trained models\n",
    "\n",
    "For the purpose of re-using some existing model, use the load() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load('testmodel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In-built function: similarity and vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The plain output of the most similar words can be printed with the function most_similar('word' or vector). \n",
    "# It is a function of the class 'model'\n",
    "# Try out 'hi','mom,'dad'...\n",
    "# What kind of similarity measure do you think is used here?\n",
    "\n",
    "model.most_similar('oops') #hi, mom, dad ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The similarity of two words can be calculated with the function similarity().\n",
    "\n",
    "model.similarity('crime','officer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The probability of a sentence\n",
    "\n",
    "#model.score([\"The fox jumped over a lazy dog\".split()])\n",
    "model.score([\"What does the fox say\".split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# No clue how to this one works\n",
    "\n",
    "model.predict_output_word(['What','does','the','fox'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate: (king - man) + woman = ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The most_similar() function takes arguments, such as positive=[] and negative=[], to add and subtract vectors.\n",
    "# What is the output for the iconic query with our Language Model?\n",
    "\n",
    "model.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### (DON'T) try out at home: GoogleNews Vectors\n",
    "\n",
    "... it might crash your memory\n",
    "\n",
    "Download corpus: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For the google data only\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# load the google word2vec model\n",
    "filename = 'GoogleNews-vectors-negative300.bin'\n",
    "model_google = KeyedVectors.load_word2vec_format(filename, binary=True)\n",
    "\n",
    "# calculate: (king - man) + woman = ?\n",
    "result = model_google.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization is the key! .....?\n",
    "\n",
    "We used to visualize our results if possible. Same goes for Word2Vec: the vectors can be plotted and visualized. Anyway, it is not unproblematic. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA    # inital reduction\n",
    "from sklearn.manifold import TSNE                   # final reduction\n",
    "import numpy as np                                  # array handling\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot, plot\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "def reduce_dimensions(model, plot_in_notebook = True):\n",
    "\n",
    "    num_dimensions = 2  # final num dimensions (2D, 3D, etc)\n",
    "\n",
    "    vectors = []        # positions in vector space\n",
    "    labels = []         # keep track of words to label our data again later\n",
    "    for word in model.wv.vocab:\n",
    "        vectors.append(model[word])\n",
    "        labels.append(word)\n",
    "\n",
    "\n",
    "    # convert both lists into numpy vectors for reduction\n",
    "    vectors = np.asarray(vectors)\n",
    "    labels = np.asarray(labels)\n",
    "    \n",
    "    # reduce using t-SNE\n",
    "    vectors = np.asarray(vectors)\n",
    "    logging.info('starting tSNE dimensionality reduction. This may take some time.')\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "        \n",
    "    # Create a trace\n",
    "    trace = go.Scatter(\n",
    "        x=x_vals,\n",
    "        y=y_vals,\n",
    "        mode='text',\n",
    "        text=labels\n",
    "        )\n",
    "    \n",
    "    data = [trace]\n",
    "    \n",
    "    logging.info('All done. Plotting.')\n",
    "    \n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduce_dimensions(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Further reading: \"Under the hood\" of gensim and Word2Vec:\n",
    "1. http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n",
    "2. http://adventuresinmachinelearning.com/gensim-word2vec-tutorial/\n",
    "3. http://www.claudiobellei.com/2018/01/07/backprop-word2vec-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
